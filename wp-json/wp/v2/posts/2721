{"id":2721,"date":"2010-06-10T07:03:00","date_gmt":"2010-06-10T15:03:00","guid":{"rendered":"https:\/\/www.ultrasaurus.com\/?p=2721"},"modified":"2010-06-10T07:03:00","modified_gmt":"2010-06-10T15:03:00","slug":"full-text-search-on-app-engine","status":"publish","type":"post","link":"https:\/\/www.ultrasaurus.com\/2010\/06\/full-text-search-on-app-engine\/","title":{"rendered":"full text search on app engine"},"content":{"rendered":"<p>I just got back from Google-sponsored hack session at RailsConf.  Google App Engine and JRuby combine to create some real awesomeness.  I created an small app that uses some classes from Lucene (written in Java) with a Rails app (written in Ruby) to search text stored in the App Engine data store.  The idea was to search English text using standard linguistic analysis to distinguish whole words, as well as find variants of the same root word (e.g. find &#8220;run&#8221; and &#8220;running&#8221; when searching for run, but don&#8217;t find &#8220;runt&#8221;).   It was helpful to read <a href=\"http:\/\/ikaisays.com\/2010\/04\/25\/jruby-in-memory-search-example-with-lucene-3-0-1\/\">prior work by Ikai Lan<\/a>.<\/p>\n<p>First I <a href=\"\/\/www.motorlogy.com\/apachemirror\/lucene\/solr\/1.4.0\/\">downloaded Solr<\/a>, which includes Lucene.   I unzipped it into ~\/src\/sdk, then I <a href=\"http:\/\/gist.github.com\/268192\">set up Rails for app engine<\/a>.  I experimented first in irb:<\/p>\n<pre>\n$ appcfg.rb run -S irb -r config\/environment\n\n&gt; require '\/Users\/sarah\/src\/sdk\/apache-solr-1.4.0\/lib\/lucene-core-2.9.1.jar'\n=&gt; []\n&gt; require '\/Users\/sarah\/src\/sdk\/apache-solr-1.4.0\/lib\/lucene-snowball-2.9.1.jar'\n=&gt; []\n&gt; java_import org.apache.lucene.analysis.snowball.SnowballAnalyzer              \n=&gt; Java::OrgApacheLuceneAnalysisSnowball::SnowballAnalyzer\n&gt; snowball = SnowballAnalyzer.new(\"English\")\n=&gt; #&lt;Java::OrgApacheLuceneAnalysisSnowball::SnowballAnalyzer:0x2a134eca&gt;\n&gt; s = StringReader.new(\"Testing Snowball\")\n=&gt; #&lt;Java::JavaIo::StringReader:0x7deb41d6&gt;\n&gt; token_stream = snowball.tokenStream(nil, s2)\n=&gt; #&lt;Java::OrgApacheLuceneAnalysisSnowball::SnowballFilter:0x439a8942&gt;\n&gt; token_stream.next.term\n=&gt; \"test\"\n<\/pre>\n<p>Then I copied the .jar files I needed into  WEB-INF\/lib<\/p>\n<pre>\n$ cp ~\/src\/sdk\/apache-solr-1.4.0\/lib\/lucene-core-2.9.1.jar  WEB-INF\/lib\/.\n$ cp ~\/src\/sdk\/apache-solr-1.4.0\/lib\/lucene-snowball-2.9.1.jar WEB-INF\/lib\/.\n<\/pre>\n<p>I ran generators to create my &#8220;content&#8221; field which is for the free-form text and another column I called index, but was mis-named, perhaps would be better to call it a &#8220;vector&#8221; or something.  In any case, what I called the &#8220;index&#8221; was for the data that we will search on and I made it a special &#8220;List&#8221; type which is fast for app engine to search whole words.<\/p>\n<pre>\n.\/script\/generate scaffold note content:string index:List -f --skip-migration\n.\/script\/generate dd_model note content:string index:List -f \n<\/pre>\n<p>Then I changed the model to use the <a href=\"http:\/\/snowball.tartarus.org\/texts\/introduction.html\">Snowball<\/a> analyzer from Lucene.  I include all of the model code below, which uses DataMapper instead of ActiveRecord so that it can use the app engine datastore which is not relational.  I was quite impressed with how concise the code was and how easy it was to mix Java classes in Ruby &#8212; I simply declared the class at the top of the file with a &#8220;java_import&#8221; and then I could call SnowballAnalyzer.new as if it were a regular Ruby class.  Pretty sweet.<\/p>\n<pre>\njava_import org.apache.lucene.analysis.snowball.SnowballAnalyzer\njava_import java.io.StringReader\n\nclass Note\n  include DataMapper::Resource\n  \n  property :id,      Serial\n  property :content, String,        :required =&gt; true, :length =&gt; 500\n  property :index,   List,          :required =&gt; true\n  timestamps :at \n\n  before :valid?, :update_index\n\n  def update_index\n    analyzer = SnowballAnalyzer.new(\"English\")\n    s = StringReader.new(content)\n    token_stream = analyzer.tokenStream(nil, s)\n\n    terms = []\n    while (token = token_stream.next) do\n      terms &lt;&lt; token.term \n    end\n    self.index = terms\n  end\nend\n<\/pre>\n<p>I then changed the index page to include a search form (joined in late night pairing by Ian McFarland) and in the controller action I could use very familiar Rails code to find the results:<\/p>\n<pre>\n    @notes = Note.all(:index =&gt; @query)\n<\/pre>\n<p>The complete code is on <a href=\"http:\/\/github.com\/ultrasaurus\/full-text-search-appengine\">github.com\/ultrasaurus\/full-text-search-appengine<\/a>.<\/p>\n<p>Create an app ID on the <a href=\"https:\/\/appengine.google.com\/\">app engine<\/a> page.  Add the app name info the config file and publish the app.<\/p>\n<pre>\nvi config.ru \n.\/script\/publish.sh \n<\/pre>\n<p>Note: this is not a complete solution.  There are all sorts of features of Lucene that aren&#8217;t surfaced in this example, most significantly ranking.  Also, the query really should be tokenized and stemmed as well as the &#8220;content&#8221; field that are being searched.<\/p>\n","protected":false},"excerpt":{"rendered":"<p>I just got back from Google-sponsored hack session at RailsConf. Google App Engine and JRuby combine to create some real awesomeness. I created an small app that uses some classes from Lucene (written in Java) with a Rails app (written in Ruby) to search text stored in the App Engine data store. The idea was&hellip; <a href=\"https:\/\/www.ultrasaurus.com\/2010\/06\/full-text-search-on-app-engine\/\">Continue reading <span class=\"meta-nav\">&rarr;<\/span><\/a><\/p>\n","protected":false},"author":84,"featured_media":0,"comment_status":"open","ping_status":"open","sticky":false,"template":"","format":"standard","meta":[],"categories":[3],"tags":[],"_links":{"self":[{"href":"https:\/\/www.ultrasaurus.com\/wp-json\/wp\/v2\/posts\/2721"}],"collection":[{"href":"https:\/\/www.ultrasaurus.com\/wp-json\/wp\/v2\/posts"}],"about":[{"href":"https:\/\/www.ultrasaurus.com\/wp-json\/wp\/v2\/types\/post"}],"author":[{"embeddable":true,"href":"https:\/\/www.ultrasaurus.com\/wp-json\/wp\/v2\/users\/84"}],"replies":[{"embeddable":true,"href":"https:\/\/www.ultrasaurus.com\/wp-json\/wp\/v2\/comments?post=2721"}],"version-history":[{"count":0,"href":"https:\/\/www.ultrasaurus.com\/wp-json\/wp\/v2\/posts\/2721\/revisions"}],"wp:attachment":[{"href":"https:\/\/www.ultrasaurus.com\/wp-json\/wp\/v2\/media?parent=2721"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https:\/\/www.ultrasaurus.com\/wp-json\/wp\/v2\/categories?post=2721"},{"taxonomy":"post_tag","embeddable":true,"href":"https:\/\/www.ultrasaurus.com\/wp-json\/wp\/v2\/tags?post=2721"}],"curies":[{"name":"wp","href":"https:\/\/api.w.org\/{rel}","templated":true}]}}